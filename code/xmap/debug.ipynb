{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "import auxiliary as auxi\n",
    "from cleanData import CleanData\n",
    "from splitData import SplitData\n",
    "from itemBasedSim import ItemBasedSim\n",
    "from extender import ExtendSim\n",
    "\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_root = \"/home/jovyan/work/data\"\n",
    "path_pickle_train = join(path_root, \"cache/two_domain/split_data/train\")\n",
    "path_pickle_test = join(path_root, \"cache/two_domain/split_data/test\")\n",
    "path_pickle_baseline_sim = join(path_root, \"cache/two_domain/item_based_sim/base_sim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testRDD = sc.pickleFile(path_pickle_test)\n",
    "item2item_simRDD = sc.pickleFile(path_pickle_baseline_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)\n",
    "itemsim = ItemBasedSim(method='cosine', num_atleast=50)\n",
    "\n",
    "item2item_simDF = itemsim.build_sim_DF(item2item_simRDD)\n",
    "\n",
    "item2item_simDF.registerTempTable(\"sim_table\")\n",
    "BB_item_list = sqlContext.sql(\n",
    "    \"SELECT DISTINCT id1 FROM sim_table WHERE label = 1\").map(\n",
    "    lambda line: line.id1).collect()\n",
    "BB_item_bd = sc.broadcast(BB_item_list)\n",
    "\n",
    "item_simRDD = itemsim.get_item_sim(item2item_simRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "extend_sim = ExtendSim(top_k)\n",
    "\n",
    "classfied_items = extend_sim.find_knn_items(item_simRDD, BB_item_bd).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_siminfo(sc, classfied_items):\n",
    "    \"\"\"broadcast knn item information.\n",
    "    arg:\n",
    "        classfied_items: iid, (BB_BB, BB_NB), (NB_BB, NB_NN)\n",
    "    return:\n",
    "        knn_BB_bd: {BB iid: {NB iid: (sum, mutu, frac_mutu)}}\n",
    "        knn_NB_bd: {NB iid: {iid: (sum, mutu, frac_mutu)}}\n",
    "    \"\"\"\n",
    "    BB_info = classfied_items.map(\n",
    "        lambda line: (line[0], line[1])).filter(\n",
    "        lambda line: line[1] is not None).cache()\n",
    "\n",
    "    NB_info = classfied_items.map(\n",
    "        lambda line: (line[0], line[2])).filter(\n",
    "        lambda line: line[1] is not None).cache()\n",
    "\n",
    "    BB_items_knn = BB_info.map(\n",
    "        lambda line: (line[0], dict(\n",
    "                (l[0], l[1:]) for l in line[1][0] + line[1][1]))\n",
    "    ).collectAsMap()\n",
    "\n",
    "    NB_items_knn = NB_info.map(\n",
    "        lambda line: (line[0], dict(\n",
    "                (l[0], l[1:]) for l in line[1][0] + line[1][1]))\n",
    "    ).collectAsMap()\n",
    "\n",
    "    knn_BB_bd = sc.broadcast(BB_items_knn)\n",
    "    knn_NB_bd = sc.broadcast(NB_items_knn)\n",
    "    return BB_info, NB_info, knn_BB_bd, knn_NB_bd\n",
    "\n",
    "BB_info, NB_info, knn_BB_bd, knn_NB_bd = extract_siminfo(sc, classfied_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_BB_withother_in_singledomain(iter_items):\n",
    "    \"\"\"combine BB item with other items for each domain.\n",
    "    return:\n",
    "        NB_NN iid, [(BB iid, [NB_NN iid*])*]\n",
    "    \"\"\"\n",
    "    for iid, (NB_BB, NB_NN) in iter_items:\n",
    "        \"\"\"\n",
    "        NB_BB: [(BB iid, sim, mutu, frac_mutu)*]\n",
    "        NB_NN: [(NN iid, sim, mutu, frac_mutu)*]\n",
    "        \"\"\"\n",
    "        for info in NB_BB:\n",
    "            yield info[0], [(iid, [line[0] for line in NB_NN])]\n",
    "\n",
    "BB_other_intra = NB_info.mapPartitions(\n",
    "    combine_BB_withother_in_singledomain).reduceByKey(lambda a, b: a + b).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        def extend_BB_source(sourceRDD):\n",
    "            \"\"\"connect BB item in target domain with items in source domain.\n",
    "            (BB_target, BB_source), connections\n",
    "            \"\"\"\n",
    "            def helper(iter_items):\n",
    "                for iid, line in iter_items:\n",
    "                    for v in knn_BB_bd.value[iid].keys():\n",
    "                        if \"T:\" in v:\n",
    "                            yield (v, iid), line\n",
    "            return sourceRDD.mapPartitions(helper)\n",
    "\n",
    "        def extend_BB_target(rdd):\n",
    "            \"\"\"connect BB item in source domain with item in target domain.\n",
    "            (BB_target, BB_source), connections\n",
    "            \"\"\"\n",
    "            def helper(iter_items):\n",
    "                for iid, line in iter_items:\n",
    "                    for v in knn_BB_bd.value[iid].keys():\n",
    "                        if \"S:\" in v:\n",
    "                            yield (iid, v), line\n",
    "            return rdd.mapPartitions(helper)\n",
    "        \n",
    "BB_other_intra_source = BB_other_intra.filter(lambda l: \"S:\" in l[0])\n",
    "BB_other_intra_target = BB_other_intra.filter(lambda l: \"T:\" in l[0])\n",
    "\n",
    "extended_BB_source = extend_BB_source(BB_other_intra_source)\n",
    "extended_BB_target = extend_BB_target(BB_other_intra_target)\n",
    "joined_extended_BB = extended_BB_source.join(extended_BB_target).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extended_BB_target.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_root = \"/home/tlin/notebooks/data\"\n",
    "path_pickle_train = join(\n",
    "    path_root, \"cache/two_domain/split_data/train\")\n",
    "path_pickle_test = join(\n",
    "    path_root, \"cache/two_domain/split_data/test\")\n",
    "path_pickle_baseline_sim = join(\n",
    "    path_root, \"cache/two_domain/item_based_sim/base_sim\")\n",
    "path_pickle_extended_sim = join(\n",
    "    path_root, \"cache/two_domain/extend_sim/extendsim\")\n",
    "path_pickle_private_mapped_sim = join(\n",
    "    path_root, \"cache/two_domain/private_mapping/privatemap\")\n",
    "path_pickle_nonprivate_mapped_sim = join(\n",
    "    path_root, \"cache/two_domain/private_mapping/nonprivatemap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingRDD = sc.pickleFile(path_pickle_train).cache()\n",
    "private_mapped_sim = sc.pickleFile(path_pickle_private_mapped_sim)\n",
    "nonprivate_mapped_sim = sc.pickleFile(path_pickle_nonprivate_mapped_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_to_dict(rdd):\n",
    "    \"\"\"For a rdd, map it from list to dict.\n",
    "    return:\n",
    "        {source item: target item}\n",
    "    \"\"\"\n",
    "    return dict((line[1], line[0]) for line in rdd.collect())\n",
    "\n",
    "private_mapped_sim_dict = map_to_dict(private_mapped_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A3J85VVGLCXD57',\n",
       "  'S:B000EMLDTG',\n",
       "  5.0,\n",
       "  datetime.datetime(2013, 1, 17, 19, 0))]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataRDD = trainingRDD.flatMap(\n",
    "    lambda line: [(line[0], l[0], l[1], l[2]) for l in line[1]]).cache()\n",
    "dataRDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mapping_item(line, mapping_dict):\n",
    "    \"\"\".\n",
    "    Args:\n",
    "        line: in the form of (uid, iid, rating, rating time).\n",
    "        mapping_dict: {source item: target item}.\n",
    "        mapping_key: it contains all keys of mapping.\n",
    "    \"\"\"\n",
    "    return (line[0], mapping_dict[line[1]], line[2], line[3]) \\\n",
    "        if line[1] in mapping_dict else None\n",
    "    \n",
    "alterEgo_profile = dataRDD.map(\n",
    "    lambda line: mapping_item(line, private_mapped_sim_dict)).filter(\n",
    "    lambda line: line is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_sthbased_profile(rdd, profile):\n",
    "    \"\"\"build an item-based or a user-based profile.\n",
    "    Args:\n",
    "        rdd: (uid, iid, rating, time)*\n",
    "    \"\"\"\n",
    "    if \"user\" in profile:\n",
    "        return rdd.map(\n",
    "            lambda l: (l[0], [(l[1], l[2], l[3])])).reduceByKey(\n",
    "            lambda a, b: a + b)\n",
    "    elif \"item\" in profile:\n",
    "        return rdd.map(\n",
    "            lambda l: (l[1], [(l[0], l[2], l[3])])).reduceByKey(\n",
    "            lambda a, b: a + b)\n",
    "    \n",
    "user_based_alterEgo = build_sthbased_profile(alterEgo_profile, \"user\").cache()\n",
    "item_based_alterEgo = build_sthbased_profile(alterEgo_profile, \"item\").cache()\n",
    "user_based_dict_bd = sc.broadcast(user_based_alterEgo.collectAsMap())\n",
    "item_based_dict_bd = sc.broadcast(item_based_alterEgo.collectAsMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    def get_info(dataRDD):\n",
    "        \"\"\"get the information of RDD, either item or user.\n",
    "        Args:\n",
    "            dataRDD could either be userRDD or itemRDD.\n",
    "            userRDD: (uid, (iid, rating, rating time)*)\n",
    "            itemRDD: (iid, (uid, rating, rating time)*)\n",
    "        Returns:\n",
    "            info of the input RDD:\n",
    "                (uid, (average, norm2, count))* or\n",
    "                (iid, (average, norm2, count))* or\n",
    "        \"\"\"\n",
    "        def norm2(ratings):\n",
    "            \"\"\"calculate the norm 2 of input ratings.\n",
    "            Args:\n",
    "                ratings: (iid, rating, rating time)*\n",
    "            Returns:\n",
    "                norm of ratings.\n",
    "            \"\"\"\n",
    "            return np.sqrt(np.sum([rating[1] ** 2 for rating in ratings]))\n",
    "\n",
    "        def average(ratings):\n",
    "            \"\"\"calculate the average of the ratings.\n",
    "            Args:\n",
    "                ratings: (iid, rating, rating time)*\n",
    "            Returns:\n",
    "                average of ratings.\n",
    "            \"\"\"\n",
    "            return 1.0 * np.average([rating[1] for rating in ratings])\n",
    "\n",
    "        def helper(line):\n",
    "            \"\"\"a helper function.\"\"\"\n",
    "            uid, ratings = line\n",
    "            return uid, (average(ratings), norm2(ratings), len(ratings))\n",
    "        return dataRDD.map(helper)\n",
    "    \n",
    "user_info = sc.broadcast(get_info(user_based_alterEgo).collectAsMap())\n",
    "item_info = sc.broadcast(get_info(item_based_alterEgo).collectAsMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    from itertools import combinations\n",
    "\n",
    "    def produce_pairwise(dataRDD):\n",
    "        \"\"\"produce pairwise.\"\"\"\n",
    "        def helper(iters):\n",
    "            \"\"\"find item pairs.\"\"\"\n",
    "            for uid, ratings in iters:\n",
    "                for item1, item2 in combinations(ratings, 2):\n",
    "                    yield (item1[0], item2[0]), [(item1[1], item2[1], uid)]\n",
    "        return dataRDD.filter(\n",
    "            lambda line: len(line[1]) >= 2).mapPartitions(\n",
    "            helper).reduceByKey(\n",
    "            lambda a, b: a + b)\n",
    "    \n",
    "pair_wise = produce_pairwise(user_based_alterEgo).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line = pair_wise.take(1)[0]\n",
    "(id1, id2), rating_pairs = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ratings = [\n",
    "    (rating_pair[0], rating_pair[1], rating_pair[0] * rating_pair[1])\n",
    "    for rating_pair in rating_pairs]\n",
    "inner_product = sum(map(lambda line: line[2], ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

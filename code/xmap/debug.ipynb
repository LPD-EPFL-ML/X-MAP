{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_root = \"/home/tlin/notebooks/data\"\n",
    "path_pickle_train = join(path_root, \"cache/two_domain/split_data/train\")\n",
    "path_pickle_test = join(path_root, \"cache/two_domain/split_data/test\")\n",
    "path_pickle_baseline_sim = join(path_root, \"cache/two_domain/item_based_sim/base_sim\")\n",
    "path_pickle_extended_sim = join(path_root, \"cache/two_domain/extend_sim/extendsim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extended_simRDD = sc.pickleFile(path_pickle_extended_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x7f2304ac5630>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_range = 1\n",
    "privacy_epsilon = 0.6\n",
    "sim_method = 'ad_cos'\n",
    "rpo = 0.1\n",
    "\n",
    "def calculate_prob(lines, replacement_selection_list):\n",
    "    \"\"\"calculate probability (not normalized).\"\"\"\n",
    "    probs = []\n",
    "    for line in zip(lines, replacement_selection_list):\n",
    "        tmp = 1.0 * np.exp(\n",
    "            privacy_epsilon * line[0][1] / (\n",
    "                2 * mapping_range * line[1][1]))\n",
    "        probs.append((line[0][0], tmp))\n",
    "    return probs\n",
    "\n",
    "def normalize_prob(prob_pairs):\n",
    "    \"\"\"normalize probability.\"\"\"\n",
    "    sum_prob = sum([pair[1] for pair in prob_pairs])\n",
    "    normalized_prob_pairs = [\n",
    "        (pair[0], pair[1] / sum_prob) for pair in prob_pairs]\n",
    "    return normalized_prob_pairs\n",
    "\n",
    "t = extended_simRDD.take(1)[0]\n",
    "\n",
    "iid, lines = t\n",
    "lines = sorted(lines, key=lambda x: - abs(x[1]))[: 10]\n",
    "\n",
    "replacement_selection_list = [\n",
    "    (line[0], 1) for line in lines]\n",
    "\n",
    "\n",
    "prob_pairs = calculate_prob(lines, replacement_selection_list)\n",
    "normalized_prob_pairs = normalize_prob(prob_pairs)\n",
    "list(map(lambda l: l[0], normalized_prob_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
